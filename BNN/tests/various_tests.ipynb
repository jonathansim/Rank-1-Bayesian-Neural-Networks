{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics.classification\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "import json \n",
    "from datetime import datetime\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "from rank1_wide_resnet import Rank1Bayesian_WideResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1 has 36518356 parameters (36470208 weights, 8986 biases)\n",
      "Model2 has 36635872 parameters (36470208 weights, 9016 biases)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36479194"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Arguments\n",
    "ensemble_size1 = 1\n",
    "ensemble_size2 = 4\n",
    "\n",
    "### Models\n",
    "model1 = Rank1Bayesian_WideResNet(depth=28, widen_factor=10, num_classes=10, ensemble_size=ensemble_size1)\n",
    "model2 = Rank1Bayesian_WideResNet(depth=28, widen_factor=10, num_classes=10, ensemble_size=ensemble_size2)\n",
    "\n",
    "### Count parameters\n",
    "def count_parameters(model):\n",
    "    all_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    weight_params = sum(p.numel() for name, p in model.named_parameters() if 'weight' in name)\n",
    "    bias_params = sum(p.numel() for name, p in model.named_parameters() if 'bias' in name)\n",
    "    return all_params, weight_params, bias_params\n",
    "\n",
    "model1_params, model1_weight_params, model1_bias_params = count_parameters(model1)\n",
    "model2_params, model2_weight_params, model2_bias_params = count_parameters(model2)\n",
    "print(f\"Model1 has {model1_params} parameters ({model1_weight_params} weights, {model1_bias_params} biases)\")\n",
    "print(f\"Model2 has {model2_params} parameters ({model2_weight_params} weights, {model2_bias_params} biases)\")\n",
    "\n",
    "\n",
    "# print(f\"Model1 has {count_parameters(model1)} parameters\")\n",
    "# print(f\"Model2 has {count_parameters(model2)} parameters\")\n",
    "\n",
    "# ### Calculate difference (absolute and percentage)\n",
    "# parameter_diff = count_parameters(model2) - count_parameters(model1)\n",
    "# percentage_diff = (parameter_diff / count_parameters(model1)) * 100\n",
    "# print(f\"Model2 has {parameter_diff} more parameters than Model1, which is a {percentage_diff:.2f}% increase\")\n",
    "\n",
    "# 36479194\n",
    "36470208 + 8986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
